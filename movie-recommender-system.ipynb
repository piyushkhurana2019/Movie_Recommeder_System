{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>in the 22nd century, a paraplegic marine is di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>captain barbossa, long believed to be dead, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>a cryptic message from bond’s past sends him o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>following the death of district attorney harve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>john carter is a war-weary, former military ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                     title  \\\n",
       "0     19995                                    Avatar   \n",
       "1       285  Pirates of the Caribbean: At World's End   \n",
       "2    206647                                   Spectre   \n",
       "3     49026                     The Dark Knight Rises   \n",
       "4     49529                               John Carter   \n",
       "\n",
       "                                                tags  \n",
       "0  in the 22nd century, a paraplegic marine is di...  \n",
       "1  captain barbossa, long believed to be dead, ha...  \n",
       "2  a cryptic message from bond’s past sends him o...  \n",
       "3  following the death of district attorney harve...  \n",
       "4  john carter is a war-weary, former military ca...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies = movies.merge(credits,on='title')\n",
    "\n",
    "movies.shape\n",
    "\n",
    "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies.isnull().sum()\n",
    "\n",
    "movies.duplicated().sum()\n",
    "\n",
    "import ast\n",
    "\n",
    "#ast.literal_eval is used to convert string into list and we can then run loop as list has indices\n",
    "\n",
    "def convert(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        L.append(i['name'])\n",
    "    return L\n",
    "\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "movies['genres'].apply(convert)\n",
    "\n",
    "movies['genres']=movies['genres'].apply(convert)\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies['keywords']=movies['keywords'].apply(convert)\n",
    "\n",
    "movies.head()\n",
    "\n",
    "def fetch_director(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job']=='Director':\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['crew']=movies['crew'].apply(fetch_director)\n",
    "\n",
    "movies.head()\n",
    "\n",
    "def convert3(obj):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter < 3:\n",
    "            L.append(i['name'])\n",
    "        counter+=1\n",
    "    return L \n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert)\n",
    "movies.head()\n",
    "\n",
    "#now overview column is a string and we want to concatenate overview, genre, cast, crew into one column i.e. tags so we need to convert overview col to list \n",
    "\n",
    "movies['overview']=movies['overview'].apply(lambda x:x.split())\n",
    "\n",
    "movies.head()\n",
    "\n",
    "#now we need to apply one transition that is we need to remove all the spaces from all the columns as for example there is a word Sam Worington and there is another word Sam Mendes now if we dont remove the spaces the tags generated will be Sam, Warington, sam, mendes now if somebody looks for sam the model get confused that which same to show therefore we need to remove spaces and make samWarington as one tag and samMendes as another\n",
    "\n",
    "movies['genres']=movies['genres'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies['cast']=movies['cast'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "movies['crew']=movies['crew'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies['tags']=movies['overview']+movies['genres']+movies['keywords']+movies['cast']+movies['crew']\n",
    "\n",
    "movies.head()\n",
    "\n",
    "new_df = movies[['movie_id','title', 'tags']]\n",
    "\n",
    "new_df.head()\n",
    "\n",
    "#now we are making this tags column as strings\n",
    "\n",
    "new_df['tags']=new_df['tags'].apply(lambda x:\" \".join(x))\n",
    "\n",
    "new_df\n",
    "\n",
    "new_df['tags']=new_df['tags'].apply(lambda x:x.lower())\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are done with data preprocessing ab hme hrr movie ka ek vector bnana h so aise hmare paas 5000 vectors ban jayenge then if koi hmse bolega ek movie k similar movies nukalne ki toh uss movie k vector k closest vale mmovies k vector dedenge..  in order to perform this vectorization we have many ways, we are using the most simpler one i.e. Bag Of Words in this technique hum saare movies k tags ko mila denge let say hmare paas 1000 words bn gye ab hum har movie m check krenge ki vo words kitni baar aa rhe h aise hrr movie k paas 1000D vector ban jayega, Note:- hum stop words ko ignore krenge(aise words jo sentence formation m help krte h like is, an, the, in, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4806, 5000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '007', '10', ..., 'zoo', 'zooeydeschanel', 'zoëkravitz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now there are so many words like (action, actions) (activity, activities) which has same meaning just different spellings so now we need to apply steming... stemin is the proces of convertiing words like (love, loved, loving) to (love, love, love) then we remove duplicates we need a library for steming named nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/piyushkhurana/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/piyushkhurana/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/piyushkhurana/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/piyushkhurana/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/piyushkhurana/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y= []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "        \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       in the 22nd century, a parapleg marin is dispa...\n",
       "1       captain barbossa, long believ to be dead, ha c...\n",
       "2       a cryptic messag from bond’ past send him on a...\n",
       "3       follow the death of district attorney harvey d...\n",
       "4       john carter is a war-weary, former militari ca...\n",
       "                              ...                        \n",
       "4804    el mariachi just want to play hi guitar and ca...\n",
       "4805    a newlyw couple' honeymoon is upend by the arr...\n",
       "4806    \"signed, sealed, delivered\" introduc a dedic q...\n",
       "4807    when ambiti new york attorney sam is sent to s...\n",
       "4808    ever sinc the second grade when he first saw h...\n",
       "Name: tags, Length: 4806, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to calculate dist between these vectors But as we know the curse of dimensionality Euclidean(tip to tip dist of vector y2-y1 ka sq x2-x1 ka sq) fails so instead we will calculate the cosine dist between vectors i.e the angle between the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
